# -*- coding: utf-8 -*-
"""CNN_naive_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kJU-WoRlBpBIyTtZJK6tZ5bjR3uYEUKg
"""

import os
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)

# load json and create model
json_file = open('model.json', 'r')
loaded_model_json = json_file.read()
json_file.close()
loaded_model = model_from_json(loaded_model_json)
# load weights into new model
loaded_model.load_weights("model.h5")
print("Loaded model from disk")

# evaluate loaded model on test data
loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])
score = loaded_model.evaluate(X, Y, verbose=0)
print("%s: %.2f%%" % (loaded_model.metrics_names[1], score[1] * 100))

def plot_results(metrics, title=None, ylabel=None, ylim=None, metric_name=None, color=None):
    fig, ax = plt.subplots(figsize=(15, 4))

    if not (isinstance(metric_name, list) or isinstance(metric_name, tuple)):
        metrics = [metrics, ]
        metric_name = [metric_name, ]

    for idx, metric in enumerate(metrics):
        ax.plot(metric, color=color[idx])

    plt.xlabel("Epoch")
    plt.ylabel(ylabel)
    plt.title(title)
    plt.xlim([0, 9])
    plt.ylim(ylim)
    # Tailor x-axis tick marks
    ax.xaxis.set_major_locator(MultipleLocator(5))
    ax.xaxis.set_major_formatter(FormatStrFormatter('%d'))
    ax.xaxis.set_minor_locator(MultipleLocator(1))
    plt.grid(True)
    plt.legend(metric_name)
    plt.show()
    plt.close()

# Set the path to the directory containing the images
#data_dir = r"C:\Users\HP\OneDrive - Technion\Desktop\Computer_homeworks\semester 6\project\Cannabis images\Project_cropped_images"
data_dir = r"C:\Users\HP\OneDrive - Technion\Desktop\Computer_homeworks\semester 6\project\Cannabis images\simulation_cropped_images"
# Define the image dimensions and number of classes
img_height, img_width = 224, 224
num_classes = 2

# Load the images into memory and create labels
X = []
y = []
for i, class_name in enumerate(os.listdir(data_dir)):
    class_path = os.path.join(data_dir, class_name)
    print("Class number ", i, "is the file ", class_name)
    for img_name in os.listdir(class_path):
        img_path = os.path.join(class_path, img_name)
        print("i: ", i, "img path:", img_path)
        if (os.path.isfile(img_path)):
          image = Image.open(img_path)
          img = image.resize((img_height, img_width))
          X.append(np.array(img) / 255.0)
          y.append(i)

# Convert the data to numpy arrays
X = np.array(X)
y = np.array(y)

#np.savetxt("x_array_values", X)
#np.savetxt("y_array_values", y)

#X = np.np.load("x_array_values.npy")
#y = np.loadtxt("y_array_values.npy")

# Split the data into training and validation sets
num_samples = X.shape[0]
indices = np.random.permutation(num_samples)
train_indices = indices[:int(0.8*num_samples)]
val_indices = indices[int(0.8*num_samples):int(0.9*num_samples)]
test_indices = indices[int(0.9*num_samples):]

train_images = X[train_indices]
train_labels = y[train_indices]
val_images = X[val_indices]
val_labels = y[val_indices]
test_images = X[val_indices]
test_labels = y[val_indices]

print(train_labels.shape)

# Convert the labels to one-hot encoding
train_labels = np.eye(num_classes)[train_labels]
val_labels = np.eye(num_classes)[val_labels]
test_labels = np.eye(num_classes)[test_labels]

print(train_labels.shape)

import tensorflow as tf
from tensorflow.python.keras.models import Sequential
from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from sklearn.model_selection import KFold

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

# Define the CNN architecture
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(64, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Conv2D(128, (3, 3), activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(2, activation='softmax'))

model.summary()

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_data=(val_images, val_labels))

train_loss = history.history["loss"]
train_acc = history.history["accuracy"]
valid_loss = history.history["val_loss"]
valid_acc = history.history["val_accuracy"]

plot_results([train_acc, valid_acc],
             ylabel="Accuracy",
             ylim=[0.0, 1.0],
             metric_name=["Training Accuracy", "Validation Accuracy"],
             color=["g", "b"])

plot_results([train_loss, valid_loss],
             ylabel="Loss",
             ylim=[0.0, 5.0],
             metric_name=["Training Loss", "Validation Loss"],
             color=["g", "b"])

# Evaluate the model
test_loss, test_acc = model.evaluate(test_images, test_labels)
print(f"Test accuracy: {test_acc*100:.3f}")
#print('Test accuracy:', test_acc, ' Test loss:', test_loss)

# Generate predictions for the test dataset.
predictions = model.predict(test_images)

# For each sample image in the test dataset, select the class label with the highest probability.
predicted_labels = [np.argmax(i) for i in predictions]

# Convert one-hot encoded labels to integers.
y_test_integer_labels = tf.argmax(test_labels, axis=1)

# Generate a confusion matrix for the test dataset.
cm = tf.math.confusion_matrix(labels=y_test_integer_labels, predictions=predicted_labels)

# Plot the confusion matrix as a heatmap.
plt.figure(figsize=[14, 7])
import seaborn as sn

sn.heatmap(cm, annot=True, fmt='d', annot_kws={"size": 12})
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('Truth')
plt.show()

# serialize model to JSON
model_json = model.to_json()
with open("model.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model.save_weights("model.h5")
print("Saved model to disk")

